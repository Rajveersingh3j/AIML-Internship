---

## 📊 Task 1: Data Preprocessing Interview Questions

### 1. What are the different types of missing data?

* **MCAR (Missing Completely at Random)**

  * Missingness is random and unrelated to any feature.
  * *Example:* A sensor randomly fails to record temperature.

* **MAR (Missing at Random)**

  * Missingness is related to observed data, not the missing value itself.
  * *Example:* Income might be missing more for younger individuals.

* **MNAR (Missing Not at Random)**

  * Missingness is related to the value of the missing data.
  * *Example:* People with high income may choose not to disclose it.

---

### 2. How do you handle categorical variables?

* **Label Encoding**

  * Assigns integer values to categories.
  * Best for **ordinal data**.
  * ⚠️ Risk of implying order for nominal features.

* **One-Hot Encoding**

  * Converts categories into binary columns.
  * Best for **nominal data**.
  * ⚠️ Can cause high dimensionality.

* **Frequency / Count Encoding**

  * Replaces category with its frequency/count.

* **Target Encoding**

  * Replaces category with the mean of the target variable.
  * ⚠️ Can lead to overfitting; use cross-validation or smoothing.

---

### 3. What is the difference between normalization and standardization?

| Feature               | Normalization             | Standardization                  |
| --------------------- | ------------------------- | -------------------------------- |
| Also called           | Min-Max Scaling           | Z-score Scaling                  |
| Formula               | `(x - min) / (max - min)` | `(x - mean) / std`               |
| Range                 | Scales data to \[0, 1]    | Centers data around 0 (mean = 0) |
| Sensitive to outliers | Yes                       | Less sensitive                   |
| Use case              | Non-Gaussian data         | Gaussian (normal) data           |

---

### 4. How do you detect outliers?

* **Statistical Methods**:

  * Z-Score: Values beyond ±3 std deviations
  * IQR: Outside Q1 - 1.5×IQR or Q3 + 1.5×IQR

* **Visualization**:

  * Boxplots, Histograms, Scatterplots

* **Model-Based**:

  * Isolation Forest, DBSCAN, One-Class SVM

* **Domain Knowledge**:

  * Business-specific rules

---

### 5. Why is preprocessing important in ML?

* Ensures **data quality and consistency**
* Helps **model convergence**
* Removes **noise and bias**
* Deals with **missing or imbalanced data**
* Reduces **training time**

---

### 6. What is one-hot encoding vs label encoding?

| Feature                           | One-Hot Encoding                   | Label Encoding           |
| --------------------------------- | ---------------------------------- | ------------------------ |
| Converts                          | Category → Binary columns          | Category → Numeric label |
| Suitable for                      | Nominal data                       | Ordinal data             |
| Example: ("Red", "Blue", "Green") | \[1, 0, 0], \[0, 1, 0], \[0, 0, 1] | 0, 1, 2                  |
| Risk                              | High dimensionality                | Implied order            |

---

### 7. How do you handle data imbalance?

* **Resampling**

  * Oversampling (SMOTE), Undersampling

* **Change Metrics**

  * Use F1-score, ROC-AUC, PR curve

* **Class Weights**

  * Use `class_weight='balanced'` in scikit-learn

* **Ensemble Methods**

  * Balanced Random Forest, EasyEnsemble

---

### 8. Can preprocessing affect model accuracy?

**Yes!**
Proper preprocessing can:

* Prevent algorithm errors (e.g., due to missing values)
* Improve learning and accuracy
* Ensure proper feature scaling and encoding
* Reduce noise and overfitting

---

## 📈 Task 2: Exploratory Data Analysis (EDA) Interview Questions

### 1. What is the purpose of EDA?

EDA helps in:

* Understanding data distributions
* Identifying outliers and missing values
* Spotting trends and relationships
* Preparing features for ML models

---

### 2. How do boxplots help in understanding a dataset?

Boxplots:

* Show median, quartiles, and spread
* Highlight outliers visually
* Allow comparison between groups
* Indicate skewness

---

### 3. What is correlation and why is it useful?

Correlation measures linear relationships between variables:

* Detect redundant features
* Select important features
* Understand dependencies

---

### 4. How do you detect skewness in data?

* Use `.skew()` method in Pandas
* Visual tools: Histograms, KDE plots, Boxplots
* Positive skew = right tail; Negative skew = left tail

---

### 5. What is multicollinearity?

Occurs when features are highly correlated with each other:

* Affects model coefficients
* Reduces interpretability
* Detect using correlation matrix or VIF (Variance Inflation Factor)

---

### 6. What tools do you use for EDA?

* **Python libraries**: Pandas, NumPy, Matplotlib, Seaborn, Plotly
* **EDA tools**: Sweetviz, Pandas Profiling, D-Tale
* **BI tools**: Excel, Power BI, Tableau

---

### 7. Can you explain a time when EDA helped you find a problem?

> "In a churn prediction project, EDA revealed a data error: tenure was incorrectly recorded in months instead of years. Boxplots exposed the anomaly. Fixing it significantly improved model performance."

---

### 8. What is the role of visualization in ML?

Visualizations help in:

* Understanding data (distribution, outliers, trends)
* Feature selection & engineering
* Model diagnostics (residuals, confusion matrix, ROC)
* Communicating insights effectively

---
